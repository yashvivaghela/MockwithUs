{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85564bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7010b54d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PyPDF2, pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0a050b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV= (r\"C:\\Users\\User\\OneDrive - Thadomal Shahani Engineering College\\Documents\\BE\\Job Matcher\\\\CV.pdf\")\n",
    "Req= (r\"C:\\Users\\User\\OneDrive - Thadomal Shahani Engineering College\\Documents\\BE\\Job Matcher\\\\Requirement (2).pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c4fd195",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_File=open(CV,'rb')\n",
    "Script=PyPDF2.PdfReader(CV_File)\n",
    "pages=len(Script.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f14873a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gary White\n",
      "Data analyst\n",
      "PERSONAL SUMMARY\n",
      "AREAS OF E XPERTISE\n",
      "A bright, talented and self-motivated data analyst who has excellent organisational\n",
      "Database adm inistration\n",
      "skills, is highly efficient and has a good eye for detail. Has extensive experience\n",
      "of\n",
      "assisting in the development and upgrading of database systems and analytical\n",
      "Data manage ment\n",
      "techniques. Able to play a key role in analysing problems and come up with creative\n",
      "solutions as well as producing methodologies and files for effective data\n",
      "Data cleaning\n",
      "management. A quick learner who can absorb new ideas and can communicate\n",
      "clearly and effectively.\n",
      "SAS, SQL, SPSS\n",
      "Now looking for a suitable data analyst position with a ambitious company.\n",
      "Relational databases\n",
      "WORK EXPERIENCE\n",
      "Database mar keting\n",
      "Consumer Energy Provider – Coventry\n",
      "Data warehou sing systems DATA ANALYST June 2008 - Present\n",
      "Collecting, collating and carrying out complex data analysis in support of\n",
      "Data analysis\n",
      "management & customer requests. Also involved in reporting statistical findings to\n",
      "work colleagues and senior managers.\n",
      "Duties:\n",
      "Manipulating, cleansing & processing data using Excel, Access and SQL.\n",
      "PROFESSIONAL\n",
      "Responsible for loading, extracting and validation of client data.\n",
      "NVQ in Busin ess Liaising with end-users and 3rd party suppliers.\n",
      "Improvement Techniques Analysing raw data, drawing conclusions & developing\n",
      "recommendations\n",
      "Writing T-SQL scripts to manipulate data for data loads and extracts.\n",
      "Developing data analytical databases from complex financial source data.\n",
      "Performing daily system checks.\n",
      "Data entry, data auditing, creating data reports & monitoring all data for\n",
      "accuracy.\n",
      "Designing, developing and implementing new functionality.\n",
      "PERSONAL SKILLS Monitoring the automated loading processes.\n",
      "Advising on the suitability of methodologies and suggesting improvements.\n",
      "Analytical\n",
      "Carrying out specified data processing and statistical techniques.\n",
      "Supplying qualitative and quantitative data to colleagues & clients.\n",
      "People skills\n",
      "Using Informatica & SAS to extract, transform & load source data from transaction\n",
      "systems.\n",
      "Evaluating\n",
      "KEY SKILLS AND COMPETENCIES\n",
      "Attention to detail & ability to work in a pressurised time sensitive environment.\n",
      "Experience running complex and high volume ETL processes.\n",
      "PERSONAL DETAILS Exposure to MIS/data warehouse applications.\n",
      "Checking of supplied data for sense, consistency and accuracy.\n",
      "Gary White Sound understanding of relational, object and dimensional databases.\n",
      "34 Anywhere R oad Extensive experience with SQL/Server T-SQL, DTS/SSIS & Excel\n",
      "2003/2007.\n",
      "Coventry\n",
      "CV6 7RF\n",
      "ACADEMIC QUALIFICATIONS\n",
      "T: 02476 888 5544\n",
      "M: 0887 222 9 999 BSc (Hons) Mathematical Science with Statistics\n",
      "E: gary.w@da yjob.co.uk Nuneaton University 2005 - 2008\n",
      "DOB: 12/09/1985 A levels: Maths (A) English (B) Technology (B) Science (C)\n",
      "Driving license: Yes Coventry Central College 2003 - 2005\n",
      "Nationality: British\n",
      "REFERENCES – Available on request.\n",
      "Copyright information - Please read\n",
      "© This data analyst CV template is the copyright of Dayjob Ltd August 2010.\n",
      "Jobseekers may download and use this CV\n",
      "example for their own personal use to help them create their own CVs. You are most\n",
      "welcome to link to this page or any other\n",
      "page on our site www.dayjob.com. However these CVs must not be distributed or made\n",
      "available on other websites without\n",
      "our prior permission. For any questions relating to the use of this CV template\n",
      "please email: info@dayjob.com.\n"
     ]
    }
   ],
   "source": [
    "Script = []\n",
    "with pdfplumber.open(CV_File) as pdf:\n",
    "    for i in range (0,pages):\n",
    "        page=pdf.pages[i]\n",
    "        text=page.extract_text()\n",
    "        print (text)\n",
    "        Script.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "967a0806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gary WhiteData analystPERSONAL SUMMARYAREAS OF E XPERTISEA bright, talented and self-motivated data analyst who has excellent organisationalDatabase adm inistrationskills, is highly efficient and has a good eye for detail. Has extensive experienceofassisting in the development and upgrading of database systems and analyticalData manage menttechniques. Able to play a key role in analysing problems and come up with creativesolutions as well as producing methodologies and files for effective dataData cleaningmanagement. A quick learner who can absorb new ideas and can communicateclearly and effectively.SAS, SQL, SPSSNow looking for a suitable data analyst position with a ambitious company.Relational databasesWORK EXPERIENCEDatabase mar ketingConsumer Energy Provider – CoventryData warehou sing systems DATA ANALYST June 2008 - PresentCollecting, collating and carrying out complex data analysis in support ofData analysismanagement & customer requests. Also involved in reporting statistical findings towork colleagues and senior managers.Duties:Manipulating, cleansing & processing data using Excel, Access and SQL.PROFESSIONALResponsible for loading, extracting and validation of client data.NVQ in Busin ess Liaising with end-users and 3rd party suppliers.Improvement Techniques Analysing raw data, drawing conclusions & developingrecommendationsWriting T-SQL scripts to manipulate data for data loads and extracts.Developing data analytical databases from complex financial source data.Performing daily system checks.Data entry, data auditing, creating data reports & monitoring all data foraccuracy.Designing, developing and implementing new functionality.PERSONAL SKILLS Monitoring the automated loading processes.Advising on the suitability of methodologies and suggesting improvements.AnalyticalCarrying out specified data processing and statistical techniques.Supplying qualitative and quantitative data to colleagues & clients.People skillsUsing Informatica & SAS to extract, transform & load source data from transactionsystems.EvaluatingKEY SKILLS AND COMPETENCIESAttention to detail & ability to work in a pressurised time sensitive environment.Experience running complex and high volume ETL processes.PERSONAL DETAILS Exposure to MIS/data warehouse applications.Checking of supplied data for sense, consistency and accuracy.Gary White Sound understanding of relational, object and dimensional databases.34 Anywhere R oad Extensive experience with SQL/Server T-SQL, DTS/SSIS & Excel2003/2007.CoventryCV6 7RFACADEMIC QUALIFICATIONST: 02476 888 5544M: 0887 222 9 999 BSc (Hons) Mathematical Science with StatisticsE: gary.w@da yjob.co.uk Nuneaton University 2005 - 2008DOB: 12/09/1985 A levels: Maths (A) English (B) Technology (B) Science (C)Driving license: Yes Coventry Central College 2003 - 2005Nationality: BritishREFERENCES – Available on request.Copyright information - Please read© This data analyst CV template is the copyright of Dayjob Ltd August 2010.Jobseekers may download and use this CVexample for their own personal use to help them create their own CVs. You are mostwelcome to link to this page or any otherpage on our site www.dayjob.com. However these CVs must not be distributed or madeavailable on other websites withoutour prior permission. For any questions relating to the use of this CV templateplease email: info@dayjob.com.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Script=''.join(Script)\n",
    "CV_Clear=Script.replace(\"\\n\",\"\")\n",
    "CV_Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd872f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Req_File=open(Req,'rb')\n",
    "Script_Req=PyPDF2.PdfReader(Req_File)\n",
    "pages=len(Script_Req.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f480a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst job summary\n",
      "A good job description starts with an attention-grabbing summary of the position and\n",
      "its role within your company. Your summary should provide an overview of your company\n",
      "and expectations for the position. Outline the types of activities and\n",
      "responsibilities required for the job so job seekers can determine if they are\n",
      "qualified, or if the job is suitable for them.\n",
      "Data Analyst responsibilities and duties\n",
      "The responsibilities and duties section is the most important part of the job\n",
      "description. Here you should outline the functions this position will perform on a\n",
      "regular basis, how the job functions within the organization and the title of the\n",
      "manager the person will report to.\n",
      "Data Analyst qualifications and skills\n",
      "Next, outline the required and preferred skills for your position. This may include\n",
      "education, previous job experience, certifications and technical skills. You may also\n",
      "include soft skills and personality traits that you expect from a successful\n",
      "candidate. While it may be tempting to include a long list of skills and\n",
      "requirements, including too many could dissuade qualified candidates from applying.\n",
      "Keep your list of qualifications concise, but provide enough detail with relevant\n",
      "keywords and terms.\n"
     ]
    }
   ],
   "source": [
    "Script_Req = []\n",
    "with pdfplumber.open(Req_File) as pdf:\n",
    "    for i in range (0,pages):\n",
    "        page=pdf.pages[i]\n",
    "        text=page.extract_text()\n",
    "        print (text)\n",
    "        Script_Req.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f027fda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Analyst job summaryA good job description starts with an attention-grabbing summary of the position andits role within your company. Your summary should provide an overview of your companyand expectations for the position. Outline the types of activities andresponsibilities required for the job so job seekers can determine if they arequalified, or if the job is suitable for them.Data Analyst responsibilities and dutiesThe responsibilities and duties section is the most important part of the jobdescription. Here you should outline the functions this position will perform on aregular basis, how the job functions within the organization and the title of themanager the person will report to.Data Analyst qualifications and skillsNext, outline the required and preferred skills for your position. This may includeeducation, previous job experience, certifications and technical skills. You may alsoinclude soft skills and personality traits that you expect from a successfulcandidate. While it may be tempting to include a long list of skills andrequirements, including too many could dissuade qualified candidates from applying.Keep your list of qualifications concise, but provide enough detail with relevantkeywords and terms.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Script_Req=''.join(Script_Req)\n",
    "Req_Clear=Script_Req.replace(\"\\n\",\"\")\n",
    "Req_Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83fa4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Test=[CV_Clear,Req_Clear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a330223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "count_matrix=cv.fit_transform(Match_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8728b9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity is : [[1.         0.47720455]\n",
      " [0.47720455 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print('Similarity is :',cosine_similarity(count_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66029206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Percentage is :47.72% to Requirement\n"
     ]
    }
   ],
   "source": [
    "MatchPercentage=cosine_similarity(count_matrix)[0][1]*100\n",
    "MatchPercentage=round(MatchPercentage,2)\n",
    "print('Match Percentage is :'+ str(MatchPercentage)+'% to Requirement')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
