{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc55724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14a4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "\n",
    "# Sampling frequency\n",
    "frequency = 44400\n",
    "\n",
    "# Recording duration in seconds\n",
    "duration = 10\n",
    "\n",
    "# to record audio from\n",
    "# sound-device into a Numpy\n",
    "\n",
    "def record_to_file(path):\n",
    "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
    "    recording = sd.rec(int(duration * frequency),\n",
    "                    samplerate = frequency, channels = 1)\n",
    "\n",
    "    # Wait for the audio to complete\n",
    "    sd.wait()\n",
    "\n",
    "    # using scipy to save the recording in .wav format\n",
    "    # This will convert the NumPy array\n",
    "    # to an audio file with the given sampling frequency\n",
    "    write(\"recording0.wav\", frequency, recording)\n",
    "\n",
    "    # using wavio to save the recording in .wav format\n",
    "    # This will convert the NumPy array to an audio\n",
    "    # file with the given sampling frequency\n",
    "    wv.write(\"recording1.wav\", recording, frequency, sampwidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5545792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2830cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please talk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 23:57:49.149443: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 462ms/step\n",
      "Predicted emotion: disgust\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "model = tf.keras.models.load_model('result/(h)Speech-Emotion-Recognition-Model.h5 ')\n",
    "print(\"Please talk\")\n",
    "filename = \"recording1.wav\"\n",
    "# record the file (start talking)\n",
    "record_to_file(filename)\n",
    "\n",
    "y, sr = librosa.load(filename, sr=22050)\n",
    "\n",
    "# Extract MFCC features\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "mfcc = np.expand_dims(mfcc.T, axis=0)\n",
    "# Predict emotion label\n",
    "predicted_probabilities = model.predict(mfcc)\n",
    "predicted_label = np.argmax(predicted_probabilities)\n",
    "# Map label index to emotion label\n",
    "emotion_labels = {0: 'disgust', 1: 'happy', 2: 'sad', 3: 'neutral', 4: 'fear', 5: 'angry'}\n",
    "predicted_emotion = emotion_labels[predicted_label]\n",
    "print(\"Predicted emotion:\", predicted_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c897f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
